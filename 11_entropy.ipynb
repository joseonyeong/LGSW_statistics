{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 파이썬 기반의 AI를 위한 기초수학, 확률및통계"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정보이론, 엔트로피\n",
    "- 정보이론 : 로지스틱회귀분석, 모형 해석\n",
    "- 엔트로피 : 머신러닝, tree 계열 알고리즘, decision tree 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정보이론 information theory\n",
    "- 정보량 : 어떤 특정 사건이 일어났을 때, 우리는 얼마나 많은 정보를 획득하였는가\n",
    "  + 확률이 낮을수록 더 놀랍다. ==> 정보량이 크다. ==> 예측이 틀렸다.\n",
    "- I(x) : 사건(x)가 주는 정보량 (단위; 비트)\n",
    "- P(x) : 시간 x가 발생할 확률\n",
    "- 로그 : log (2진법, 비트 기준) 사용\n",
    "- 예시\n",
    "    - 내일 비 올 확률 1/2 ==> 1.0 bit\n",
    "    - 로또 당첨 1/800백만 ==> 23 bit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 엔트로피\n",
    "- H(x) : 확률변수 X의 엔트로피 평균 정보량\n",
    "- P(x) : 각 사건의 확률\n",
    "- 쉬운 예제 : 앞면, 뒷면 확률 = 0.5\n",
    "  + 각각 정보량 : log0.5 = 1 bit\n",
    "  + 엔트로피 : H = 0.5 * 1 + 0.5 * 1 = 1 bit\n",
    "  + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.5)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 각 사건의 확률\n",
    "probs = [0.5, 0.25, 0.5]\n",
    "\n",
    "# 각 사건의 정보량\n",
    "info = [-np.log2(p) for p in probs]\n",
    "\n",
    "# 평균 정보량 : 엔트로피\n",
    "entropy = np.sum([p * i for p, i in zip(probs, info)])\n",
    "entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 엔트로피의 활용\n",
    "$$\n",
    "H = - \\sum_{i=1}^{k} p_i \\log_2 p_i\n",
    "$$ \n",
    "\n",
    "- 남/여 성별 구분하는 예측 문제\n",
    "  + 남/여 => 클래스\n",
    "- 엔트로피 = 0 -> 완전히 순수\n",
    "- 엔트로피 = 1 -> 섞여 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 분포: {np.str_('no'): np.int64(4), np.str_('yes'): np.int64(4)}\n",
      "엔트로피: 1.0000 비트\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# 예: 분할된 데이터의 클래스 레이블\n",
    "labels = ['yes', 'no', 'yes', 'yes', 'no', 'yes', 'no', 'no']  # yes: 4, no: 4 → 완전 섞임\n",
    "\n",
    "# 클래스별 비율 구하기\n",
    "values, counts = np.unique(labels, return_counts=True)\n",
    "probs = counts / counts.sum()\n",
    "\n",
    "# 엔트로피 계산\n",
    "entropy = -np.sum(probs * np.log2(probs))\n",
    "\n",
    "print(f\"클래스 분포: {dict(zip(values, counts))}\")\n",
    "print(f\"엔트로피: {entropy:.4f} 비트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "클래스 분포: {np.str_('no'): np.int64(1), np.str_('yes'): np.int64(4)}\n",
      "엔트로피: 0.7219 비트\n"
     ]
    }
   ],
   "source": [
    "labels = ['yes', 'yes', 'yes', 'yes', 'no']  # yes: 4, no: 1\n",
    "\n",
    "# 같은 방식으로 계산\n",
    "# 클래스별 비율 구하기\n",
    "values, counts = np.unique(labels, return_counts=True)\n",
    "probs = counts / counts.sum()\n",
    "\n",
    "# 엔트로피 계산\n",
    "entropy = -np.sum(probs * np.log2(probs))\n",
    "\n",
    "print(f\"클래스 분포: {dict(zip(values, counts))}\")\n",
    "print(f\"엔트로피: {entropy:.4f} 비트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 강봉주 \n",
    "## bonjour.kang@gmail.com\n",
    "##\n",
    "## 정보이론\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "import matplotlib.pyplot as plt\n",
    "from pgmpy.factors.discrete import JointProbabilityDistribution as JPD\n",
    "import pgmpy\n",
    "\n",
    "pgmpy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.   , 0.693])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제\n",
    "# 동전 던지기\n",
    "pk = [1/2, 1/2]\n",
    "np.round([entropy(pk, base=2), entropy(pk, base=np.e)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.585, 1.792])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 주사위 던지기\n",
    "pk = 1/6*np.ones(6)\n",
    "np.round([entropy(pk, base=2), entropy(pk, base=np.e)], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.657)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제\n",
    "# 결합 엔트로피\n",
    "pk = 1/15 * np.array([2, 4, 3, 1, 1, 4])\n",
    "log_pk = -np.log(pk)\n",
    "H_XY = np.dot(pk, log_pk)\n",
    "H_XY.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+----------+\n",
      "| X    | Y    |   P(X,Y) |\n",
      "+======+======+==========+\n",
      "| X(0) | Y(0) |   0.1333 |\n",
      "+------+------+----------+\n",
      "| X(0) | Y(1) |   0.2667 |\n",
      "+------+------+----------+\n",
      "| X(0) | Y(2) |   0.2000 |\n",
      "+------+------+----------+\n",
      "| X(1) | Y(0) |   0.0667 |\n",
      "+------+------+----------+\n",
      "| X(1) | Y(1) |   0.0667 |\n",
      "+------+------+----------+\n",
      "| X(1) | Y(2) |   0.2667 |\n",
      "+------+------+----------+\n"
     ]
    }
   ],
   "source": [
    "# 예제\n",
    "# 조건부 엔트로피\n",
    "\n",
    "# 결합 확률 정의\n",
    "prob = 1/15 * np.array([2, 4, 3, 1, 1, 4])\n",
    "fxy = JPD(['X', 'Y'],[2, 3], prob)\n",
    "print(fxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "| X    |   P(X) |\n",
      "+======+========+\n",
      "| X(0) | 0.6667 |\n",
      "+------+--------+\n",
      "| X(1) | 0.3333 |\n",
      "+------+--------+\n"
     ]
    }
   ],
   "source": [
    "# 조건부 확률 예시\n",
    "prob = fxy.conditional_distribution([('Y', 0)], inplace=False)\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.613)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 조건부 엔트로피 계산\n",
    "res_sum = []\n",
    "\n",
    "# 모든 x에 대하여\n",
    "for i in fxy.state_names['X']:\n",
    "    # 모든 y에 대하여\n",
    "    for j in fxy.state_names['Y']:\n",
    "        cond_y = fxy.conditional_distribution([('Y', j)], inplace=False).values[i]\n",
    "        res = -fxy.values[i,j] * np.log(cond_y)\n",
    "        res_sum.append(res)\n",
    "# 결과\n",
    "np.sum(res_sum).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.613)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# H(X, Y) - H(Y) 이용\n",
    "# H(X, Y) 계산\n",
    "H_XY = np.dot(fxy.values.reshape(-1) ,-np.log(fxy.values.reshape(-1)))\n",
    "\n",
    "# H_Y 계산\n",
    "prob_y = fxy.marginal_distribution(['Y'], inplace=False).values\n",
    "H_Y = np.dot(prob_y ,-np.log(prob_y))\n",
    "\n",
    "# 결과 계산\n",
    "np.round(H_XY-H_Y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.06)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제\n",
    "# 상호 정보 계산\n",
    "\n",
    "# 결합 확률 정의\n",
    "pxy = 1/15 * np.array([2, 4, 3, 1, 1, 4])\n",
    "fxy = JPD(['X', 'Y'],[2, 3], pxy)\n",
    "\n",
    "# 주변확률 계산\n",
    "px = fxy.marginal_distribution(['X'], inplace=False).values\n",
    "py = fxy.marginal_distribution(['Y'], inplace=False).values\n",
    "\n",
    "# 상호 정보 계산\n",
    "h_xy = np.dot(pxy, -np.log(pxy))\n",
    "h_x = np.dot(px, -np.log(px))\n",
    "h_y = np.dot(py, -np.log(py))\n",
    "\n",
    "# 결과\n",
    "i_xy = h_x + h_y - h_xy\n",
    "i_xy.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.099)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예제\n",
    "# 교차 엔트로피 계산\n",
    "px = [1/4, 1/2, 1/4]\n",
    "qx = [1/3, 1/3, 1/3]\n",
    "\n",
    "hpq = np.dot(px, -np.log(qx))\n",
    "hpq.round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
